<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.2.1">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2021-11-30T19:35:52+09:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Jung-Log</title><subtitle>즐겁게 사는 개발자 지영입니다.</subtitle><entry><title type="html">ARKIT by Apple</title><link href="http://localhost:4000/application/2021/11/30/ARKit.html" rel="alternate" type="text/html" title="ARKIT by Apple" /><published>2021-11-30T19:13:25+09:00</published><updated>2021-11-30T19:13:25+09:00</updated><id>http://localhost:4000/application/2021/11/30/ARKit</id><content type="html" xml:base="http://localhost:4000/application/2021/11/30/ARKit.html">&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;본 게시물은 2021.07 ~ 08 한샘에서 AR 가구 배치 어플리케이션을 개발할 때, 공부했던 내용입니다.&lt;/li&gt;
  &lt;li&gt;Hanssem AR(Augmented Reality) Placement application development&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(21/07/01 - 21/08/31)&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;hr /&gt;

&lt;h1 id=&quot;1-arkit&quot;&gt;1. ARKIT?&lt;/h1&gt;

&lt;p&gt;&lt;strong&gt;iOS 기기를 위한 Apple의 AR 개발 플랫폼&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;→ iOS 기기의 카메라와 움직임들을 어플 또는 게임 내에서 증강 현실을 구현하기 위해 통합하는 프레임워크&lt;/p&gt;

&lt;p&gt;→ ARKIT는 기기의 움직임 추적, 카메라 장면 캡처 등 AR을 구현하기 위해 필요한 기술들을 결합해서 AR구현을 단순화하고, 이렇게 단순화 된 ARKIT 프래임워크를 사용해서 개발자들은 여러 종류의 AR을 기기의 정면, 후면 카메라를 이용해서 구현할 수 있을 것.&lt;/p&gt;

&lt;p&gt;→ 2017년 6월 처음 출시&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-west-2.amazonaws.com/secure.notion-static.com/e16a9e3f-1882-4bde-92d0-c9f83de7a8df/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20211130%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20211130T101725Z&amp;amp;X-Amz-Expires=86400&amp;amp;X-Amz-Signature=d63f645ae7db82e5fb6ff8c931502311408412bfdcb75971a46275f188b01bba&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=filename%20%3D%22Untitled.png%22&amp;amp;x-id=GetObject&quot; alt=&quot;ARKIT&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;💡 ARKIT은 mac 내 Simulator로 구동 불가, ARKIT 사용 위해서는 iOS 11 이상의 기기와 Xcode 9 이상의 개발 환경 필요.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;Tutorial&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://www.youtube.com/watch?v=f3xFpRWZEz8&quot;&gt;https://www.youtube.com/watch?v=f3xFpRWZEz8&lt;/a&gt;
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;1-1-arkit-algorithm&quot;&gt;1-1. ARKIT algorithm&lt;/h2&gt;

&lt;p&gt;VIO(Visual-Inertial Odometry)라는 기술을 활용하여 스마트폰이 주변의 실제 환경에 대한 상대적인 위치를 이해한다.&lt;/p&gt;

&lt;h3 id=&quot;1-모션-추적&quot;&gt;1) 모션 추적&lt;/h3&gt;

&lt;p&gt;→ RGB 카메라 센서에서 오는 시각 데이터와 모션 데이터를 결합하여 accelerometer and gyroscope sensors 고대비의 위치 계산 (스마트폰의 IMU 센서)&lt;/p&gt;

&lt;p&gt;→ 가상 카메라의 위치와 방향을 얻을 수 있다. (Feature points)&lt;/p&gt;

&lt;h3 id=&quot;2-장면-이해&quot;&gt;2) 장면 이해&lt;/h3&gt;

&lt;p&gt;→ 여러 Feature points이 동일 평면에 있는 위치를 이해하는데에 집중&lt;/p&gt;

&lt;p&gt;→ 스마트폰이 감지하는 평면의 위치를 찾을 수 있음&lt;/p&gt;

&lt;h3 id=&quot;3-rendering&quot;&gt;3) Rendering&lt;/h3&gt;

&lt;p&gt;→ 가상의 물체를 고정된 anchor위에 배치&lt;/p&gt;

&lt;p&gt;Arcore가 feature points의 확장에 조금 더 중점을 둔다면,&lt;/p&gt;

&lt;p&gt;Arkit는 feature points들을 이용한 수직, 수평 → 평면 detection에 중점을 둔다. 
&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;2-arkit-기능&quot;&gt;2. ARKIT 기능&lt;/h1&gt;

&lt;p&gt;현재 ARKIT은 4까지 (2021/06) 출시된 상황&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;ARKIT Framework Tree&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;a href=&quot;https://developer.apple.com/documentation/arkit&quot;&gt;Apple Developer Documentation&lt;/a&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-1-depth-api&quot;&gt;2-1. Depth API&lt;/h2&gt;

&lt;p&gt;아이폰 12 pro부터 탑재된 LIDAR 스캐너 내 고급 장면 인식 기능을 통해 주변 환경에 대한 픽셀당 Depth 정보를 사용할 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;💡 LIDAR : 사물에 레이저를 쏘고 빛이 반사되어 돌아오는 시간을 통해 사물까지 거리 값 (Depth) 측정하는 센서
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;해당 Depth 정보를 Scene Geometry에서 생성된 3D 매시 데이터와 결합하면 가상 3D Object를 즉각적으로 배치하고 실제 환경에 원활하게 혼합하여 가상의 사물 오클루전을 더 사실적으로 구현할 수 있다. 이를 통해 더 정밀한 측정 및 사용자 환경에 효과 적용 등 앱 내에서 새로운 기능을 구현할 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;💡 Occlusion (가림 효과) : 실제 사물 뒤에 가상 contents가 있을 때, 실제 사물에 의해 가상 contents가 가려지도록 하는 효과
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-2-location-anchor&quot;&gt;2-2. Location Anchor&lt;/h2&gt;

&lt;p&gt;유명 랜드마크 및 도시의 곳곳 특정 위치에서 AR 경험을 구현할 수 있다. 위치 Anchor를 통해 특정 위도, 경도 및 고도 좌표에 AR 창작물을 고정할 수 있으며, 사용자는 카메라 렌즈를 통해 실제 물체를 보는 것처럼 가상 물체를 움직이고 다른 시각에서 확인할 수 있다. 
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-3-얼굴-추적-기능-지원-확대&quot;&gt;2-3. 얼굴 추적 기능 지원 확대&lt;/h2&gt;

&lt;p&gt;&lt;strong&gt;얼굴 추적 기능&lt;/strong&gt; (얼굴을 인식하고 ARKIT 상 좌표계 (x, y, z) 축 오버레이, 각 눈의 위치 및 방향 추적)에 대한 지원이 iPhone SE를 포함하여 A12 Bionic 칩 이상이 탑재된 모든 기기의 전면 카메라로 확대되어, 더 많은 사용자가 전면 카메라를 사용하여 AR 경험을 즐길 수 있다. TrueDepht 카메라를 사용하여 한번에 최대 3명의 얼굴을 추적하면서 미모티콘 및 Snapchat와 같은 전면 카메라 경험을 지원한다. 
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-4-scene-geometry&quot;&gt;2-4. Scene Geometry&lt;/h2&gt;

&lt;p&gt;Scene Geometry로 바닥, 벽, 천장, 창문, 문, 좌석을 식별하는 레이블을 사용하여 공간의 토폴로지 맵을 만들 수 있다. 이처럼 실제 세계에 대한 심층적 이해를 통해 가상 물체에 대한 사물 occlusion 및 실제 물리적 요소를 구현하고 AR 작업 흐름을 구동하는 데 필요한 정보를 더 많이 얻을 수 있다. 
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-5-lidar-스캐너-이용&quot;&gt;2-5. LIDAR 스캐너 이용&lt;/h2&gt;

&lt;p&gt;LIDAR 스캐너를 사용하여 AR 물체를 스캔 없이 현실 세계에 즉각적으로 배치할 수 있다. 즉각적인 AR 배치 기능은 별도의 코드 변경 없이 iPhone 12 Pro, iPhone 12 Pro Max, iPad Pro에서 ARKIT으로 빌드한 모든 앱에 대해 자동으로 활성화 된다.
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-6-인물-occlusion&quot;&gt;2-6. 인물 occlusion&lt;/h2&gt;

&lt;p&gt;AR 콘텐츠를 현실 세계에 있는 인물의 앞이나 뒤에 사실적으로 표시하면서 AR 경험을 더 몰입감 있게 만드는 동시에 대부분의 환경에서 ‘그린’ 화면 스타일 효과를 적용할 수 있다. Depth 추정은 별도의 코드 변경 없이 iPhone 12 Pro, iPhone 12 Pro Max, iPad Pro에서 ARKIT으로 빌드한 모든 앱에 대해 자동으로 활성화 된다.
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-7-모션-캡처&quot;&gt;2-7. 모션 캡처&lt;/h2&gt;

&lt;p&gt;한 대의 카메라로 사람의 움직임을 실시간으로 캡쳐한다. 몸의 위치와 움직임을 일련의 관절과 뼈로 파악하여 AR 경험에 동작과 자세를 입력하면서 AR의 중심에 인물을 배치할 수 있다. 높이 추정은 별도의 코드 변경 없이, iPhone 12 Pro, iPhone 12 Pro Max, iPad Pro에서 ARKIT으로 빌드한 모든 앱에 대해 자동으로 활성화 된다.
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-8-전-후면-카메라-동시-지원&quot;&gt;2-8. 전 후면 카메라 동시 지원&lt;/h2&gt;

&lt;p&gt;전면 카메라, 후면 카메라로 얼굴과 공간을 동시에 추적할 수 있어 새로운 가능성이 열린다. 예를 들어 사용자는 자신의 얼굴만을 사용해 후면 카메라 뷰에 보이는 AR 콘텐츠와 상호 작용할 수 있다. 
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-9-다중-얼굴-추적&quot;&gt;2-9. 다중 얼굴 추적&lt;/h2&gt;

&lt;p&gt;ARKIT 얼굴 추적 기능은 Apple Neural Engine과 전면 카메라가 탑재된 모든 기기에서 한번에 최대 3명의 얼굴을 추적하면서 미모티콘 및 Snapchat과 같은 AR 경험을 지원한다.
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-10-협업-세션&quot;&gt;2-10. 협업 세션&lt;/h2&gt;

&lt;p&gt;여러 사람들과의 실시간 협업 세션을 사용하여 공동으로 AR 앱을 제작할 수 있으므로 AR 경험을 더욱 빠르게 개발하고 사용자들이 공유 AR 경험을 멀티 플레이어 게임처럼 즐기게 할 수 있다. 
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;2-11-추가-개선-사항&quot;&gt;2-11. 추가 개선 사항&lt;/h2&gt;

&lt;p&gt;→ 한 번에 최대 100개의 이미지를 인식하고 해당 이미지에 있는 물체의 실제 크기를 자동으로 추정한다.&lt;/p&gt;

&lt;p&gt;→ 복잡한 환경의 물체 인식이 개선되면서 3D 물체 인식이 더 강력해졌다.&lt;/p&gt;

&lt;p&gt;→ 이제 머신 러닝을 사용하여 환경에서 더욱 빠르게 평면을 감지할 수 있다. 
&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;3-arkit-or-arcore&quot;&gt;3. ARKIT or ARCORE?&lt;/h1&gt;

&lt;p&gt;→ ARKIT : 2017년 6월&lt;/p&gt;

&lt;p&gt;→ ARCORE : 2018년 3월&lt;/p&gt;

&lt;p&gt;BUT, ARCORE는 TANGO 플랫폼에서 발전한 플랫폼으로 ARKIT에 비해 크게 뒤쳐지지 않음&lt;/p&gt;

&lt;h2 id=&quot;3-1-지원-기능&quot;&gt;3-1. 지원 기능&lt;/h2&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-west-2.amazonaws.com/secure.notion-static.com/0f4fec80-23d7-4527-a8e1-4e059007a621/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20211130%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20211130T101821Z&amp;amp;X-Amz-Expires=86400&amp;amp;X-Amz-Signature=ac5056f36119a7bb7e6c2f0d503b7ea308a490a5b95dff69ba19434c83a94e3a&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=filename%20%3D%22Untitled.png%22&amp;amp;x-id=GetObject&quot; alt=&quot;ARKIT2&quot; /&gt;&lt;/p&gt;

&lt;p&gt;기본적으로 제공하는 기능은 거의 동일하나&lt;/p&gt;

&lt;p&gt;ARKIT → 3D Object Tracking / Body Tracking, 전 후면 카메라 동시 지원, Multiple Face Tracking의 &lt;strong&gt;추가적인 SDK 지원&lt;/strong&gt;
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;3-2-범용성&quot;&gt;3-2. 범용성&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;ARCORE&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Android, iOS, Windows10에서 전부 구동 가능&lt;/p&gt;

&lt;p&gt;Document → Unity, Unreal, Android, iOS 제공&lt;/p&gt;

&lt;p&gt;Opensource&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;ARKIT&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;iOS에서만 구동 가능하며 폐쇄적으로 Document, Opensource 제공 X
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;3-3-인식-기능-algorithm-방식&quot;&gt;3-3. 인식 기능 (Algorithm 방식)&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;ARCORE&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Feature Points를 최대한 많이 찾아, Mapping된 공간 영역을 빠르게 확장&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;ARKIT&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;수평, 수직으로 평면을 감지하는 기술이 정확
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;3-4-지원-디바이스&quot;&gt;3-4. 지원 디바이스&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;ARCORE&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Google/ 하웨이/ LG/ 삼성/ 샤오미/ Apple 등 폭넓은 디바이스 지원&lt;/p&gt;

&lt;p&gt;→ 하드웨어 성능, 지원하는 센서에 따라 ARCORE 성능이 많이 달라짐&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;ARKIT&lt;/strong&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;iPhone / iPad 의 iOS 기기만 지원&lt;/p&gt;

&lt;p&gt;→ True Depth 카메라가 장착되어 있어 정확도가 상당히 높은 인식 기술 제공&lt;/p&gt;

&lt;p&gt;→ 특히 LIDAR 부착된 장치의 경우, 고해상도의 Depth Map을 얻을 수 있어 AR 세계의 공간을 분석하고 인식하는 기술이 더욱 향상됨. 
&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;4--class&quot;&gt;4.  CLASS&lt;/h1&gt;

&lt;h2 id=&quot;4-1-arconfiguration&quot;&gt;4-1. ARConfiguration&lt;/h2&gt;

&lt;p&gt;→ AR에 필요한 것들을 구성하기 위한 추상 Class.&lt;/p&gt;

&lt;p&gt;→ 이를 상속받은 8개의 서브클래스가 실질적인 작업을 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-west-2.amazonaws.com/secure.notion-static.com/89290f1b-444a-4087-8591-408c673c1a4b/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20211130%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20211130T101846Z&amp;amp;X-Amz-Expires=86400&amp;amp;X-Amz-Signature=7f9886431963334cdbd2d8dce6897b945a080d77eb83dde425301ce6fe7120e1&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=filename%20%3D%22Untitled.png%22&amp;amp;x-id=GetObject&quot; alt=&quot;ARKIT3&quot; /&gt;&lt;/p&gt;

&lt;p&gt;→ ARWorldTrackingConfiguration&lt;/p&gt;

&lt;p&gt;ARkit 기본 기능 제공, 사용자가 거주하는 실제 세계를 추적하고 가상 콘텐츠를 배치할 좌표 공간과 일치시킴&lt;/p&gt;

&lt;p&gt;가상의 물체는 현실 세계의 카메라가 어떻게 움직이더라도 같은 곳에 위치해야 한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-west-2.amazonaws.com/secure.notion-static.com/943deb0e-4606-4b76-bcfa-dffd342b17d0/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20211130%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20211130T101908Z&amp;amp;X-Amz-Expires=86400&amp;amp;X-Amz-Signature=5caffd310374995f412b26f9d5ce999af042ec5cf5fe0cf3db921c9c213c649c&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=filename%20%3D%22Untitled.png%22&amp;amp;x-id=GetObject&quot; alt=&quot;ARKIT4&quot; /&gt;&lt;/p&gt;

&lt;p&gt;기기의 움직임을 3개의 회전각(roll, pitch, yaw)과 3개의 변환각 (x, y, z)을 통해 추적한다. 
&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;5-scenekit&quot;&gt;5. SCENEKIT&lt;/h1&gt;

&lt;p&gt;Scenekit는 앱에서 3D 애니메이션 장면과 효과를 만드는 데 도움이 되는 고급 3D 그래픽 프래임워크.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-west-2.amazonaws.com/secure.notion-static.com/f734e9a7-41d8-438b-9833-62630a6a698d/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20211130%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20211130T101924Z&amp;amp;X-Amz-Expires=86400&amp;amp;X-Amz-Signature=dae484382715ae1604dc36586322649ed1cc47d750939c6a65e783463437fa8a&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=filename%20%3D%22Untitled.png%22&amp;amp;x-id=GetObject&quot; alt=&quot;ARKIT5&quot; /&gt;&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;모바일 환경에서 증강현실 혹은 3D 모델 랜더링을 요하는 어플리케이션을 개발할 때, OpenGL이나 Apple의 Metal과 같은 그래픽 API들을 표준으로 삼음.&lt;/p&gt;

&lt;/blockquote&gt;

&lt;blockquote&gt;
  &lt;p&gt;하지만 개발 시 매우 어려운 난이도나, 비효율성 등의 여러 문제 때문에 graphics rendering engine을 필요로 함 → &lt;strong&gt;SpriteKit, SceneKit&lt;/strong&gt;&lt;/p&gt;

  &lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;5-1-spritekit&quot;&gt;5-1. SpriteKit&lt;/h2&gt;

&lt;p&gt;→ 단순 규모에서 2D 애니메이션을 위해 디자인 됨.&lt;/p&gt;

&lt;p&gt;→ 개발자들에게 2D 애니메이션을 위한 모든 툴 제공.
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h2 id=&quot;5-2-scenekit&quot;&gt;5-2. SceneKit&lt;/h2&gt;

&lt;p&gt;→ Core Animation Framework를 기반으로, SpriteKit에 비해 고성능 옵션을 제공하며, 사용시 상당한 수학과 기하학 요구&lt;/p&gt;

&lt;p&gt;→ high-level 3D graphics framework로서, rendering engine과 descriptive API로 움직이는 장면을 만들기 위해 사용된다.&lt;/p&gt;

&lt;p&gt;→ Metal과 같은 lower-level-API보다는 복잡하다.&lt;/p&gt;

&lt;p&gt;→ Loin OS에서 배포되었으며, 개발자들이 보다 쉽게 복잡한 3D 장면을 만들 수 있도록 디자인 됨.&lt;/p&gt;

&lt;p&gt;→ VR 용으로 고안되엇으며 ARKIT과 함께 사용할 수 밖에 없음.&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;@IBOutlet&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;weak&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;sceneView&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SCNView&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;sceneView&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scene&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SCNScene&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;sceneView&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;autoenablesDefaultLighting&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kc&quot;&gt;true&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;boxNode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SCNNode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;boxNode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geometry&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;SCNBox&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;width&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;height&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;length&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;chamferRadius&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;boxNode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geometry&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;?&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;firstMaterial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;?&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lightingModel&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;physicallyBased&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;boxNode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geometry&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;?&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;firstMaterial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;?&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;diffuse&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contents&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;UIColor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;red&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;boxNode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;geometry&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;?&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;firstMaterial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;?&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;metalness&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;contents&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;1.0&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;sceneView&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scene&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;?&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;rootNode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;addChildNode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;boxNode&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;→ 기본 View는 SCNView&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;보통 AR 증강현실 APP에서는 SceneKit를 사용해 왔음.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;→ SceneKit은 Contents들을 트리구조를 활용해서 실행.&lt;/p&gt;

&lt;p&gt;→ root 노드는 시각적인 요소를 가지지 않으며, 해당 Scene world의 좌표를 정함.&lt;/p&gt;

&lt;p&gt;→ 자식 노드들은 root 노드의 scene world 내에서 시각적인 요소로 존재하는 원리.&lt;/p&gt;

&lt;aside&gt;
💡 Node (SCNNode) : root노드에 상대적인 좌표 위치 변환 속성을 제공함 (position, orientation, scale)

&lt;/aside&gt;

&lt;p&gt;→ 보는 방향이 -z축 방향을 가리키는 우회 좌표계를 사용한다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-west-2.amazonaws.com/secure.notion-static.com/0500914b-4c24-443a-8702-a059a6b1d51d/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20211130%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20211130T101941Z&amp;amp;X-Amz-Expires=86400&amp;amp;X-Amz-Signature=9051302c6c9808c9a8ade6aaab6d427816d1f1cdb2f824d2c6f41b33c458df4e&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=filename%20%3D%22Untitled.png%22&amp;amp;x-id=GetObject&quot; alt=&quot;ARKIT6&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;strong&gt;SCENEKIT은 2017년 이후로 더 이상 업데이트 되지 않음&lt;/strong&gt;&lt;/p&gt;

&lt;p&gt;→ 점점 사라질 예정&lt;/p&gt;

&lt;p&gt;→ 하지만 아직도 RealityKit 2.0보다 몇몇 이점이 존재한다. 
&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;6-realitykit-20&quot;&gt;6. RealityKit 2.0&lt;/h1&gt;

&lt;p&gt;기본 ARKit 통합, 물리적 요소 기반의 랜더링, 변형 및 스켈레톤 애니메이션, 공간 오디오 및 강체 물리 요소를 통해 AR 개발을 빠르고 쉽게 수행할 수 있게 해주는 프레임워크.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-west-2.amazonaws.com/secure.notion-static.com/12284363-6f7d-475e-8bc8-1f9e184a9e45/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20211130%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20211130T102000Z&amp;amp;X-Amz-Expires=86400&amp;amp;X-Amz-Signature=143593cf85739e7bf8fe3d5b18d8c8dd04763f57bf87088c5cd52ba142e630a4&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=filename%20%3D%22Untitled.png%22&amp;amp;x-id=GetObject&quot; alt=&quot;ARKIT7&quot; /&gt;&lt;/p&gt;

&lt;p&gt;→ Apple의 랜더링 기술 제품군에서 가장 최신 SDK (2019년 출시)&lt;/p&gt;

&lt;p&gt;→ AR/ VR 프로젝트 용으로 제작되었으며, iOS, mac에서 사용 가능&lt;/p&gt;

&lt;p&gt;→ 다중 스레드 렌더링&lt;/p&gt;

&lt;p&gt;→ LIDAR 스캐너 지원&lt;/p&gt;

&lt;p&gt;→ 독립적으로 사용 가능하며, ARKIT, MetalKit와 함께 사용할 수 있다.&lt;/p&gt;

&lt;p&gt;→ iPhone OS 15에서부터 접근 가능&lt;/p&gt;

&lt;div class=&quot;language-swift highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;@IBOutlet&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;weak&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;var&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;arView&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ARView&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;!&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;box&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;MeshResource&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;generateBox&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;mf&quot;&gt;0.5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;material&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;PhysicallyBasedMaterial&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;model&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;ModelEntity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;mesh&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;box&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;materials&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;material&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;let&lt;/span&gt; &lt;span class=&quot;nv&quot;&gt;anchor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;AnchorEntity&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nv&quot;&gt;world&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;-&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;anchor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;addChild&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;arView&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;scene&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;anchors&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nf&quot;&gt;append&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;anchor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;→ 기본 View는 ARView&lt;/p&gt;</content><author><name></name></author><category term="Application" /><category term="ARKit" /><category term="Hanssem" /><category term="ar" /><summary type="html">본 게시물은 2021.07 ~ 08 한샘에서 AR 가구 배치 어플리케이션을 개발할 때, 공부했던 내용입니다. Hanssem AR(Augmented Reality) Placement application development</summary></entry><entry><title type="html">ARCORE by Google</title><link href="http://localhost:4000/application/2021/11/30/ARcore.html" rel="alternate" type="text/html" title="ARCORE by Google" /><published>2021-11-30T19:04:25+09:00</published><updated>2021-11-30T19:04:25+09:00</updated><id>http://localhost:4000/application/2021/11/30/ARcore</id><content type="html" xml:base="http://localhost:4000/application/2021/11/30/ARcore.html">&lt;p&gt;&lt;br /&gt;&lt;/p&gt;
&lt;ul&gt;
  &lt;li&gt;본 게시물은 2021.07 ~ 08 한샘에서 AR 가구 배치 어플리케이션을 개발할 때, 공부했던 내용입니다.&lt;/li&gt;
  &lt;li&gt;Hanssem AR(Augmented Reality) Placement application development&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;(21/07/01 - 21/08/31)&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;hr /&gt;

&lt;h1 id=&quot;1-arcore-&quot;&gt;1. ARCORE ?&lt;/h1&gt;

&lt;p&gt;ARCORE은 AR 경험을 빌드하기 위한 Google의 플랫폼이며, 다양한 API를 사용하여 휴대폰에서 가상 contents를 볼 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;💡 Android 7.0 (Nougat) 이상 Android 휴대폰에서 작동하도록 설계.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;기본적으로 ARCORE는 두 가지 작업을 수행한다.&lt;/p&gt;

&lt;ol&gt;
  &lt;li&gt;모바일 장치가 이동할 때 그 위치를 추적한다.&lt;/li&gt;
  &lt;li&gt;실제 세계에 대한 지속적인 이해를 구축한다. 
&lt;br /&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;▶ ARCORE의 동작 추적 기술은 Android 카메라를 사용하여 features(Interesting points)를 추출한다. 또한 해당 points들의 시간에 따른 움직임을 추적한다.&lt;/p&gt;

&lt;p&gt;▶ points들을 추출하는 것 뿐만 아닌, plain(평면) detection을 감지할 수 있고, 주변 영역의 평균 조명 값을 추정할 수 있다. ARCORE는 이러한 모든 기능들이 결합되어, 카메라로 실제로 촬영되는 공간에 대한 자체 이해를 구축한다. 따라서 촬영되는 현실 세계에 대한 구축된 이해를 바탕으로 객체, 주석, 또는 기타 정보 등을 가상으로 배치할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-west-2.amazonaws.com/secure.notion-static.com/8ced052f-6b5c-45bc-8419-f09c13da8051/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20211130%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20211130T063243Z&amp;amp;X-Amz-Expires=86400&amp;amp;X-Amz-Signature=a0e3d37e958a9e068fc6b2ca4047333273da48087e44eeb4f231411ead4b880f&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=filename%20%3D%22Untitled.png%22&amp;amp;x-id=GetObject&quot; alt=&quot;ARCORE Flow&quot; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;
&lt;h1 id=&quot;2-fundamental-concepts&quot;&gt;2. Fundamental concepts&lt;/h1&gt;

&lt;h3 id=&quot;2-1-motion-tracking&quot;&gt;2-1. Motion tracking&lt;/h3&gt;

&lt;p&gt;실제 환경을 촬영하고 있는 핸드폰이 움직일 때, ARCORE은 ‘simultaneous localization and mapping’ (= SLAM) 이라는 process를 사용하여 주변 환경과 관련된 위치를 파악한다. ARCORE는 카메라의 이미지에서 시각적으로 구분되는 특징인 ‘Feature points’를 감지하고 이를 통하여 위치의 변화를 감지한다.  해당 points들은 IMU(관성 측정 장비)의 관성 측정치와 결합되며, 시간이 지남에 따라 전 세계를 기준으로 현재 카메라가 촬영하고 있는 장소의 ‘Pose’ (Position and Orientation)를 추정하게 된다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;💡 SLAM은 주로 자율 주행 차량에 사용되며, 기기의 주변 환경 지도를 작성하는 동시에, 기기의 위치를 작성된 지도 안에서 인식하는 기법이다. 
이 알고리즘을 통해 기기는 미지의 환경에 대한 지도를 작성할 수 있으며, 엔지니어는 지도 정보를 활용하여 환경 파악 및 장애물 회피 등의 작업을 수행할 수 있다.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;💡 SLAM process는 조금 더 광범위한 의미로 COM(concurrent odometry and mapping) process라고도 불린다.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;▶ 3D contents를 rendering하는 가상 카메라의 Pose와 ARCORE에서 제공하는 나의 핸드폰 장치 카메라의  Pose를 일치 시킨다. 따라서 개발자는 올바른 위치에 가상 3D contents를  rendering할 수 있으며, 핸드폰 장치에서 촬영되고 있는 화면과 rendering되는 가상 이미지가 겹쳐져 가상 contents가 실제 촬영되고 있는 세계의 일부인 것처럼 보이게 한다.
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2-2-environmental-understanding&quot;&gt;2-2. Environmental understanding&lt;/h3&gt;

&lt;p&gt;ARCORE는 feature points와 plane(평면)을 감지함으로써 현실 세계에 대한 이해도를 지속적으로 높인다.&lt;/p&gt;

&lt;p&gt;ARCORE는 테이블이나 벽과 같은 일반적인 수직이나 수평의 표면에 있는 것처럼 보이는 feature points의 cluster(군집들)를 찾고, 이러한 표면들을 APP 상에서 plane으로 사용할 수 있도록 한다. ARCORE는 또한 각 평면의 경계를 결정하고, 해당 정보를 앱에 제공할 수 있다. 따라서 평면과, 평면의 경계 등의 여러 정보들을 사용하여 plane에 가상 개체를 배치할 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;💡 ARCORE는 feature points(시각적으로 구분되는 점)들을 사용하여 plane을 감지하기 때문에, 
질감과 물건이 없는 흰색 벽, 평면은 제대로 감지되지 않을 수 있다.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2-3-depth-understanding&quot;&gt;2-3. Depth understanding&lt;/h3&gt;

&lt;p&gt;ARCORE는 지원되는 Android 장치의 기본 RGB 카메라를 사용하여 points들과 표면 사이의 거리에 대한 데이터를 포함하는 깊이 맵을 만들 수 있다. 깊이 맵에서 제공하는 정보를 사용하여 가상 contents를 관찰된 표면과 정확하게 맞닿게 하거나, 실제 개체의 앞이나 뒤에 표시되도록 하는 등, 사실적인 사용자 화면을 구현할 수 있다.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://codelabs.developers.google.com/codelabs/arcore-depth?hl=ko#0&quot;&gt;ARCore 깊이 | Google Codelabs&lt;/a&gt;
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2-4-light-estimation&quot;&gt;2-4. Light estimation&lt;/h3&gt;

&lt;p&gt;ARCORE는 환경의 조명에 대한 정보를 감지하고, 주어진 카메라 이미지에 대한 평균 강도와 색상 보정을 제공할 수 있다. 해당 정보를 사용하여 주변 환경과 동일한 조건에서 가상 contents를 비추어 현실감을 높인다. 
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2-5-user-interaction&quot;&gt;2-5. User interaction&lt;/h3&gt;

&lt;p&gt;ARCORE는 hit testing을 사용하여 휴대 전화 화면상의 (x, y) 좌표를 취하고, 카메라의 세계에서 광선을 투과하여 모든 평면과 광선이 교차하는 feature points, 세계 공간에서 교차하는 pose들을 활용하여 사용자는 환경에서 개체를 선택하거나 다른 방식으로 상호작용 할 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;💡 Hit testing은 적중 테스트라고 하며, 포인트(터치 포인트 등)이 화면에 그려진 그래픽 객체(UIView 등)과 만나는지 여부를 결정하는 Process이다. 
사용자가 기기 화면을 Tap하면 ARCORE는 해당 (x,y) 좌표에서 광선이 뻗어나간다 가정하고, 
해당 광선이 교차하는 모든 plane, feature points, pose를 반환한다. 
해당 결과로 Anchor를 만들게 된다.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;c1&quot;&gt;// Create a hit test using the Depth API.&lt;/span&gt;
&lt;span class=&quot;nc&quot;&gt;List&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;lt;&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;HitResult&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hitResultList&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;frame&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;hitTest&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tap&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nc&quot;&gt;HitResult&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hit&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hitResultList&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Trackable&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trackable&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getTrackable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;trackable&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;instanceof&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Plane&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trackable&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;instanceof&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Point&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;o&quot;&gt;||&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;trackable&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;instanceof&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;DepthPoint&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;n&quot;&gt;doSomething&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;hit&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;createAnchor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;
&lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;err&quot;&gt; &lt;/span&gt; &lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;→ Android App에서 Depth function 사용 시 Hit testing
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2-6-oriented-points&quot;&gt;2-6. Oriented points&lt;/h3&gt;

&lt;p&gt;방향이 지정된 점을 사용하여 각진 표면에 가상 contents를 배치할 수 있다. 여러 points를 반환하는 hit testing을 수행할 때, ARCORE는 가까운 feature points를 보고, 이를 사용하여 주어진 feature points에서 표면의 각도를 추정한다. ARCORE는 해당 각도를 고려한 pose를 반환한다.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nc&quot;&gt;Pose&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;objectPose&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;currentAnchor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;].&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getPose&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;→ .getPose(); 사용하여 특정 Point의 Pose 반환 가능&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;💡 ARCORE는 표면의 각도를 감지하기 위해 feature points를 사용하기 때문에, 흰색 벽과 같은 질감이 없는 표면은 제대로 감지되지 않을 수 있다.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2-7-anchors-and-trackables&quot;&gt;2-7. Anchors and trackables&lt;/h3&gt;

&lt;p&gt;ARCORE가 자신의 위치와 환경에 대한 이해를 향상 시키면서 pose가 변경될 수 있다. 가상 objects를 배치하려면 ARCORE가 시간이 경과됨에 따라 개체의 위치를 추적하도록 가상의 마커 역할을 하는 ‘Anchor’를 정의해야 한다. 보통 hit testing에서 반환된 pose를 기반으로 Anchor를 만들고 사용한다.&lt;/p&gt;

&lt;p&gt;pose가 변경될 수 있다는 사실은, ARCORE가 시간이 지남에 따라 평면과 feature points와 같은 환경적 object들에 대한 위치 변경 정보를 업데이트 할 수 있다는 의미이다. plane들과 points는 ‘trackable’라고 불리는 특수한 타입의 object들이다. 이름에서 알 수 있듯이 이는 ARCORE가 시간이 지남에 따라 추적할 개체들이다. 가상 object들을 ‘trackable’ object들에 고정하여 휴대폰 장치가 움직일 때에도, 둘 사이의 관계는 안정적으로 유지되도록 할 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;💡 Anchor는 CPU costs를 발생시키므로, 가능하면 재사용하며 더 이상 필요하지 않을 시 detach한다.
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-west-2.amazonaws.com/secure.notion-static.com/eee43188-bb4d-4b44-ac6a-d2fa1d7e7051/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20211130%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20211130T063933Z&amp;amp;X-Amz-Expires=86400&amp;amp;X-Amz-Signature=617914cd02ac4ff0db6d8d5d8a5830b176dd4eaf8a2c3764872b43fc666290ce&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=filename%20%3D%22Untitled.png%22&amp;amp;x-id=GetObject&quot; alt=&quot;ARCORE Flow2&quot; /&gt;&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;nc&quot;&gt;Anchor&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;anchor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;hitResult&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;createAnchor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;();&lt;/span&gt; 
&lt;span class=&quot;c1&quot;&gt;// plane tap시 hitresult 에서 anchor 생성&lt;/span&gt;
&lt;span class=&quot;nc&quot;&gt;AnchorNode&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;anchorNode&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;new&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;AnchorNode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;anchor&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;);&lt;/span&gt; 
&lt;span class=&quot;c1&quot;&gt;// 공간에 anchor을 기반으로 자동으로 배치되는 Node(Node : 하나의 오브젝트가 차지하는 영역)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;anchorNode&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;setParent&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;arFragment&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getArSceneView&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;().&lt;/span&gt;&lt;span class=&quot;na&quot;&gt;getScene&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;());&lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// (getScene : 장면 반환 / getArSceneView : 장면 랜더링(arsceneview) 반환) &lt;/span&gt;
&lt;span class=&quot;c1&quot;&gt;// -&amp;gt; parentNode로 set&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2-8-augmented-images&quot;&gt;2-8. Augmented Images&lt;/h3&gt;

&lt;p&gt;Augmented Images는 특정 2D 이미지에 응답할 수 있는 AR app을 구축하는 기능이다. 사용자가 휴대 전화의 카메라로 특정 이미지를 촬영할 때, AR 경험을 트리거할 수 있다.&lt;/p&gt;

&lt;p&gt;ARCORE는 흔들리는 2D 이미지 또한 추적할 수 있다.&lt;/p&gt;

&lt;p&gt;이미지를 오프라인으로 컴파일하여 이미지 데이터베이스를 만들거나, 개별 이미지를 장치에서 실시간으로 추가할 수 있다. 해당 이미지가 등록될 때 마다, ARCORE는 이러한 이미지, 이미지의 경계들을 감지하고 해당 pose를 반환하게 된다. 
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2-9-sharing&quot;&gt;2-9. Sharing&lt;/h3&gt;

&lt;p&gt;ARCORE Cloud Anchor API를 사용하여 Android 및 iOS장치 용 협업 또는 멀티 플레이어 앱을 만들 수 있다.&lt;/p&gt;

&lt;p&gt;하나의 장치가 hosting을 위해 Anchor와 주변 feature points를 cloud로 전송한다. 이러한 Anchor는 동일한 환경의 Android 또는 iOS 장치에서 다른 사용자와 공유할 수 있다. 이를 통해 app은 이러한 Anchor에 연결된 동일한 3D object를 rendering하여 사용자가 동시에 동일한 AR 경험을 가질 수 있다.
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;2-10-arcore-elements&quot;&gt;2-10. ARCORE ELEMENTS&lt;/h3&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-west-2.amazonaws.com/secure.notion-static.com/11aad0b8-7ea8-4128-bf98-402b1ae6f5d9/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20211130%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20211130T063955Z&amp;amp;X-Amz-Expires=86400&amp;amp;X-Amz-Signature=4f290e2d67132c03a31b547e0de86b80f264160b360307efd02d81879fc8c8ae&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=filename%20%3D%22Untitled.png%22&amp;amp;x-id=GetObject&quot; alt=&quot;ARCORE&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;3-arcore--opengl&quot;&gt;3. ARCORE + OPENGL&lt;/h1&gt;

&lt;h3 id=&quot;3-1-open-graphics-library--opengl&quot;&gt;3-1. Open Graphics Library = OpenGL&lt;/h3&gt;

&lt;p&gt;3D 그래픽인 3차원 그래픽 응용프로그램을 만들기 위한 API이며, 여러 기능 지원.&lt;/p&gt;

&lt;p&gt;→ 점, 선, 면 등과 같은 3차원 요소와 비트맵 등의 2차원 요소의 표현, 변환, 행렬을 통한 이들 요소의 변형&lt;/p&gt;

&lt;p&gt;→ RGBA 모델과 INDEXED COLOR모델에 의한 색상 지원&lt;/p&gt;

&lt;p&gt;→ 다양한 조명과 쉐이딩 설정&lt;/p&gt;

&lt;p&gt;→ 텍스쳐 매핑&lt;/p&gt;

&lt;p&gt;→ Antialiasing, Blending, Motion Blur… 등등
&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;3-2-why-not&quot;&gt;3-2. Why Not&lt;/h3&gt;

&lt;ul&gt;
  &lt;li&gt;ARCORE를 사용할 때, ARCORE가 제공하는 기본적인 기능을 이용하여 feature point를 추출하고 point cloud를 구성, plane을 인식하기 까지의 과정을 직접 제어해주는 방법&lt;/li&gt;
  &lt;li&gt;각 데이터를 사용하기 위해 OpenGL을 이용한 rendering 과정이나 데이터 처리과정도 거쳐야 하므로 작업이 좀 까다로움
&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;4-arcore--sceneform&quot;&gt;4. ARCORE + SCENEFORM&lt;/h1&gt;

&lt;h3 id=&quot;4-1-sceneform&quot;&gt;4-1. Sceneform&lt;/h3&gt;

&lt;p&gt;→ ARCORE에서 제공하는 3D Framework&lt;/p&gt;

&lt;p&gt;→ High-level scene graph API&lt;/p&gt;

&lt;p&gt;→ Filament에서 제공하는 Realistic physically based renderer&lt;/p&gt;

&lt;p&gt;→ Android Studio plugin for importing, viewing, and building 3D assets.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;💡 OpenGL 없이도 AR, 비 AR app에서 사실적인 3D 장면 rendering 가능
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h3 id=&quot;4-2-sceneform-sdk-version-1160&quot;&gt;4-2. Sceneform SDK version 1.16.0&lt;/h3&gt;

&lt;p&gt;→ open source.&lt;/p&gt;

&lt;p&gt;&lt;a href=&quot;https://github.com/google-ar/sceneform-android-sdk&quot;&gt;google-ar/sceneform-android-sdk&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;→ Build with application as a Gradle module.&lt;/p&gt;

&lt;p&gt;→ &lt;strong&gt;Supports glTF&lt;/strong&gt; instead of SFA and SFB Sceneform formats.
&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;5-arcore-methods&quot;&gt;5. ARCORE METHODS&lt;/h1&gt;

&lt;h3 id=&quot;5-1interfaces&quot;&gt;5-1.Interfaces&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/72294509/144005515-57a6f1fb-668e-409b-bbd7-6a80719377c9.JPG&quot; alt=&quot;Interfaces&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;5-2classes&quot;&gt;5-2.Classes&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/72294509/144005518-d377c03a-2a15-4868-81b6-42d811c9bf35.JPG&quot; alt=&quot;Classes&quot; /&gt;&lt;/p&gt;
&lt;h3 id=&quot;5-3enums&quot;&gt;5-3.Enums&lt;/h3&gt;
&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/72294509/144005508-8177111e-e9be-4285-b7fc-a93181b1fa0c.JPG&quot; alt=&quot;Enums1&quot; /&gt;
&lt;img src=&quot;https://user-images.githubusercontent.com/72294509/144005513-78068e4d-2ea5-4194-a1b3-90fc4dc70d0b.JPG&quot; alt=&quot;Enums2&quot; /&gt;
&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;&lt;/p&gt;

&lt;h1 id=&quot;6-develop&quot;&gt;6. DEVELOP&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;ARCORE + SCENEFORM 방식을 활용하여 Hanssem AR Furniture placement app을 개발하도록 한다.&lt;/li&gt;
  &lt;li&gt;3D objects → .glb file 형식&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&quot;https://s3.us-west-2.amazonaws.com/secure.notion-static.com/f088f9c5-5cca-4303-a6ee-644bae67056e/Untitled.png?X-Amz-Algorithm=AWS4-HMAC-SHA256&amp;amp;X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&amp;amp;X-Amz-Credential=AKIAT73L2G45EIPT3X45%2F20211130%2Fus-west-2%2Fs3%2Faws4_request&amp;amp;X-Amz-Date=20211130T064023Z&amp;amp;X-Amz-Expires=86400&amp;amp;X-Amz-Signature=733c2e802f4b4499254c0d1f711a52cf6e4ad12f436a08f2590cc50cc6497f7b&amp;amp;X-Amz-SignedHeaders=host&amp;amp;response-content-disposition=filename%20%3D%22Untitled.png%22&amp;amp;x-id=GetObject&quot; alt=&quot;ARCORE2&quot; /&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;가구 선택 부분 및 모델 연결을 제외한 &lt;strong&gt;‘배치’&lt;/strong&gt; 기능과 &lt;strong&gt;‘길이 측정’&lt;/strong&gt; 기능 중점적으로 개발
&lt;br /&gt;&lt;br /&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&quot;6-1-coding&quot;&gt;6-1. Coding&lt;/h3&gt;

&lt;p&gt;fragment로 구현 된 프로젝트&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;fragment&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;→ FragmentActivity 내의 어떤 동작 또는 사용자 인터페이스의 일부&lt;/p&gt;

&lt;p&gt;→ Activity의 모듈식 세션&lt;/p&gt;

&lt;p&gt;→ AR 시스템 상태를 관리하고 세션 수명주기 처리 ( ARCORE API의 주요 진입 점 )&lt;/p&gt;

&lt;p&gt;→ 카메라 이미지와 장치 Pose에 접근할 수 있는 Frame을 수신할 수 있다.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ArFragment&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;arFragment&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Renderable&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;renderable&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;ul&gt;
  &lt;li&gt;ArFragment&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;AR APP의 필수 요소, ARCORE의 기본 구성 요소들을 사용하게 해주는 SCENEFORM fragment.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Renderable&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Node(하나의 Object가 차지하는 영역)에 연결하여 하나의 Object를 3D 공간에서 rendering 하기 위한 기본 Class&lt;/p&gt;</content><author><name></name></author><category term="Application" /><category term="ARCORE" /><category term="Hanssem" /><category term="ar" /><summary type="html">본 게시물은 2021.07 ~ 08 한샘에서 AR 가구 배치 어플리케이션을 개발할 때, 공부했던 내용입니다. Hanssem AR(Augmented Reality) Placement application development</summary></entry><entry><title type="html">Jung-Log</title><link href="http://localhost:4000/intro/" rel="alternate" type="text/html" title="Jung-Log" /><published>2021-11-30T00:55:25+09:00</published><updated>2021-11-30T00:55:25+09:00</updated><id>http://localhost:4000/Introduce</id><content type="html" xml:base="http://localhost:4000/intro/">&lt;h3&gt;Jung-Log 시작하기&lt;/h3&gt;

&lt;p&gt;👩‍💻 안녕하세요 정지영입니다.&lt;/p&gt;
&lt;p&gt;📚 동국대학교 소프트웨어 구조 연구실 학부 연구생입니다.
&lt;p&gt;💻 웹과 앱 개발을 하고 싶어요 &lt;/p&gt;
&lt;p&gt;💻 특히 JavaScript와 Swift에 관심이 많습니다. &lt;/p&gt;&lt;br /&gt;
&lt;p&gt;새로 알게 되는 것들, 배운 것들을 정리할 공간이 필요하다고 막연하게만 생각했는데, 드디어 블로그를 시작하게 되었습니다.&lt;br /&gt;
&lt;br /&gt;고민할 시간에 부딫히며 몰입하고, 주변 사람들을 소중히 여기며 일하는 개발자가 되고 싶습니다. 개발을 하는 것이 전부가 아닌, 끊임없는 성장을 위해 달리고자 합니다.
&lt;br /&gt;이를 위해 수많은 실패에도 좌절하지 않고, 배울 점을 전부 뽑을 때까지 돌려보내고 싶지 않습니다. 저는 패배주의에서 벗어나고, 운을 끌어들이는 삶을 살고 싶기 때문이죠.&lt;br /&gt;
&lt;br /&gt;개발자로 일하며 제 성과에 대한 인정을 받을 때, 저는 가장 행복한 삶을 살아갈 수 있을 것 같습니다.&lt;br /&gt;
행복하고 즐겁게 살기 위해 열심히 노력해볼게요!&lt;/p&gt;
&lt;p&gt;- 미래의 리더 개발자 정지영&lt;/p&gt;
&lt;/p&gt;</content><author><name></name></author><category term="Introduce" /><category term="intro" /><summary type="html">Jung-Log 시작하기</summary></entry><entry><title type="html">Category</title><link href="http://localhost:4000/categories/" rel="alternate" type="text/html" title="Category" /><published>2021-11-30T00:55:25+09:00</published><updated>2021-11-30T00:55:25+09:00</updated><id>http://localhost:4000/second</id><content type="html" xml:base="http://localhost:4000/categories/"></content><author><name></name></author><category term="categories" /><summary type="html"></summary></entry></feed>