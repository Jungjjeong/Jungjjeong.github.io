I"L<p><br /></p>
<ul>
  <li>본 게시물은 2021.07 ~ 08 한샘에서 AR 가구 배치 어플리케이션을 개발할 때, 공부했던 내용입니다.</li>
  <li>Hanssem AR(Augmented Reality) Placement application development</li>
</ul>

<p>(21/07/01 - 21/08/31)</p>

<p><br /><br /></p>
<hr />

<h1 id="1-arkit">1. ARKIT?</h1>

<p><strong>iOS 기기를 위한 Apple의 AR 개발 플랫폼</strong></p>

<p>→ iOS 기기의 카메라와 움직임들을 어플 또는 게임 내에서 증강 현실을 구현하기 위해 통합하는 프레임워크</p>

<p>→ ARKIT는 기기의 움직임 추적, 카메라 장면 캡처 등 AR을 구현하기 위해 필요한 기술들을 결합해서 AR구현을 단순화하고, 이렇게 단순화 된 ARKIT 프래임워크를 사용해서 개발자들은 여러 종류의 AR을 기기의 정면, 후면 카메라를 이용해서 구현할 수 있을 것.</p>

<p>→ 2017년 6월 처음 출시</p>

<p><img src="ARKIT%20by%20Apple%206407f08947234b0d81d09eca0ff82f4f/Untitled.png" alt="ARKIT%20by%20Apple%206407f08947234b0d81d09eca0ff82f4f/Untitled.png" /></p>

<aside>
💡 ARKIT은 mac 내 Simulator로 구동 불가, ARKIT 사용 위해서는 iOS 11 이상의 기기와 Xcode 9 이상의 개발 환경 필요.

</aside>

<ul>
  <li>Tutorial</li>
</ul>

<p><a href="https://www.youtube.com/watch?v=f3xFpRWZEz8">https://www.youtube.com/watch?v=f3xFpRWZEz8</a></p>

<h2 id="1-1-arkit-algorithm">1-1. ARKIT algorithm</h2>

<p>VIO(Visual-Inertial Odometry)라는 기술을 활용하여 스마트폰이 주변의 실제 환경에 대한 상대적인 위치를 이해한다.</p>

<p><code class="language-plaintext highlighter-rouge">1) 모션 추적</code></p>

<p>→ RGB 카메라 센서에서 오는 시각 데이터와 모션 데이터를 결합하여 accelerometer and gyroscope sensors 고대비의 위치 계산 (스마트폰의 IMU 센서)</p>

<p>→ 가상 카메라의 위치와 방향을 얻을 수 있다. (Feature points)</p>

<p><code class="language-plaintext highlighter-rouge">2) 장면 이해</code></p>

<p>→ 여러 Feature points이 동일 평면에 있는 위치를 이해하는데에 집중</p>

<p>→ 스마트폰이 감지하는 평면의 위치를 찾을 수 있음</p>

<p><code class="language-plaintext highlighter-rouge">3) Rendering</code></p>

<p>→ 가상의 물체를 고정된 anchor위에 배치</p>

<p>Arcore가 feature points의 확장에 조금 더 중점을 둔다면,</p>

<p>Arkit는 feature points들을 이용한 수직, 수평 → 평면 detection에 중점을 둔다. 
<br /><br /><br /><br /></p>

<h1 id="2-arkit-기능">2. ARKIT 기능</h1>

<p>현재 ARKIT은 4까지 (2021/06) 출시된 상황</p>

<ul>
  <li>ARKIT Framework Tree</li>
</ul>

<p><a href="https://developer.apple.com/documentation/arkit">Apple Developer Documentation</a></p>

<h2 id="2-1-depth-api">2-1. Depth API</h2>

<p>아이폰 12 pro부터 탑재된 LIDAR 스캐너 내 고급 장면 인식 기능을 통해 주변 환경에 대한 픽셀당 Depth 정보를 사용할 수 있다.</p>

<aside>
💡 LIDAR : 사물에 레이저를 쏘고 빛이 반사되어 돌아오는 시간을 통해 사물까지 거리 값 (Depth) 측정하는 센서

</aside>

<p>해당 Depth 정보를 Scene Geometry에서 생성된 3D 매시 데이터와 결합하면 가상 3D Object를 즉각적으로 배치하고 실제 환경에 원활하게 혼합하여 가상의 사물 오클루전을 더 사실적으로 구현할 수 있다. 이를 통해 더 정밀한 측정 및 사용자 환경에 효과 적용 등 앱 내에서 새로운 기능을 구현할 수 있다.</p>

<aside>
💡 Occlusion (가림 효과) : 실제 사물 뒤에 가상 contents가 있을 때, 실제 사물에 의해 가상 contents가 가려지도록 하는 효과

</aside>
<p><br /><br /></p>

<h2 id="2-2-location-anchor">2-2. Location Anchor</h2>

<p>유명 랜드마크 및 도시의 곳곳 특정 위치에서 AR 경험을 구현할 수 있다. 위치 Anchor를 통해 특정 위도, 경도 및 고도 좌표에 AR 창작물을 고정할 수 있으며, 사용자는 카메라 렌즈를 통해 실제 물체를 보는 것처럼 가상 물체를 움직이고 다른 시각에서 확인할 수 있다. 
<br /><br /></p>

<h2 id="2-3-얼굴-추적-기능-지원-확대">2-3. 얼굴 추적 기능 지원 확대</h2>

<p><strong>얼굴 추적 기능</strong> (얼굴을 인식하고 ARKIT 상 좌표계 (x, y, z) 축 오버레이, 각 눈의 위치 및 방향 추적)에 대한 지원이 iPhone SE를 포함하여 A12 Bionic 칩 이상이 탑재된 모든 기기의 전면 카메라로 확대되어, 더 많은 사용자가 전면 카메라를 사용하여 AR 경험을 즐길 수 있다. TrueDepht 카메라를 사용하여 한번에 최대 3명의 얼굴을 추적하면서 미모티콘 및 Snapchat와 같은 전면 카메라 경험을 지원한다. 
<br /><br /></p>

<h2 id="2-4-scene-geometry">2-4. Scene Geometry</h2>

<p>Scene Geometry로 바닥, 벽, 천장, 창문, 문, 좌석을 식별하는 레이블을 사용하여 공간의 토폴로지 맵을 만들 수 있다. 이처럼 실제 세계에 대한 심층적 이해를 통해 가상 물체에 대한 사물 occlusion 및 실제 물리적 요소를 구현하고 AR 작업 흐름을 구동하는 데 필요한 정보를 더 많이 얻을 수 있다. 
<br /><br /></p>

<h2 id="2-5-lidar-스캐너-이용">2-5. LIDAR 스캐너 이용</h2>

<p>LIDAR 스캐너를 사용하여 AR 물체를 스캔 없이 현실 세계에 즉각적으로 배치할 수 있다. 즉각적인 AR 배치 기능은 별도의 코드 변경 없이 iPhone 12 Pro, iPhone 12 Pro Max, iPad Pro에서 ARKIT으로 빌드한 모든 앱에 대해 자동으로 활성화 된다.
<br /><br /></p>

<h2 id="2-6-인물-occlusion">2-6. 인물 occlusion</h2>

<p>AR 콘텐츠를 현실 세계에 있는 인물의 앞이나 뒤에 사실적으로 표시하면서 AR 경험을 더 몰입감 있게 만드는 동시에 대부분의 환경에서 ‘그린’ 화면 스타일 효과를 적용할 수 있다. Depth 추정은 별도의 코드 변경 없이 iPhone 12 Pro, iPhone 12 Pro Max, iPad Pro에서 ARKIT으로 빌드한 모든 앱에 대해 자동으로 활성화 된다.
<br /><br /></p>

<h2 id="2-7-모션-캡처">2-7. 모션 캡처</h2>

<p>한 대의 카메라로 사람의 움직임을 실시간으로 캡쳐한다. 몸의 위치와 움직임을 일련의 관절과 뼈로 파악하여 AR 경험에 동작과 자세를 입력하면서 AR의 중심에 인물을 배치할 수 있다. 높이 추정은 별도의 코드 변경 없이, iPhone 12 Pro, iPhone 12 Pro Max, iPad Pro에서 ARKIT으로 빌드한 모든 앱에 대해 자동으로 활성화 된다.
<br /><br /></p>

<h2 id="2-8-전-후면-카메라-동시-지원">2-8. 전 후면 카메라 동시 지원</h2>

<p>전면 카메라, 후면 카메라로 얼굴과 공간을 동시에 추적할 수 있어 새로운 가능성이 열린다. 예를 들어 사용자는 자신의 얼굴만을 사용해 후면 카메라 뷰에 보이는 AR 콘텐츠와 상호 작용할 수 있다. 
<br /><br /></p>

<h2 id="2-9-다중-얼굴-추적">2-9. 다중 얼굴 추적</h2>

<p>ARKIT 얼굴 추적 기능은 Apple Neural Engine과 전면 카메라가 탑재된 모든 기기에서 한번에 최대 3명의 얼굴을 추적하면서 미모티콘 및 Snapchat과 같은 AR 경험을 지원한다.
<br /><br /></p>

<h2 id="2-10-협업-세션">2-10. 협업 세션</h2>

<p>여러 사람들과의 실시간 협업 세션을 사용하여 공동으로 AR 앱을 제작할 수 있으므로 AR 경험을 더욱 빠르게 개발하고 사용자들이 공유 AR 경험을 멀티 플레이어 게임처럼 즐기게 할 수 있다. 
<br /><br /></p>

<h2 id="2-11-추가-개선-사항">2-11. 추가 개선 사항</h2>

<p>→ 한 번에 최대 100개의 이미지를 인식하고 해당 이미지에 있는 물체의 실제 크기를 자동으로 추정한다.</p>

<p>→ 복잡한 환경의 물체 인식이 개선되면서 3D 물체 인식이 더 강력해졌다.</p>

<p>→ 이제 머신 러닝을 사용하여 환경에서 더욱 빠르게 평면을 감지할 수 있다. 
<br /><br /><br /><br /></p>

<h1 id="3-arkit-or-arcore">3. ARKIT or ARCORE?</h1>

<p>→ ARKIT : 2017년 6월</p>

<p>→ ARCORE : 2018년 3월</p>

<p>BUT, ARCORE는 TANGO 플랫폼에서 발전한 플랫폼으로 ARKIT에 비해 크게 뒤쳐지지 않음</p>

<h2 id="3-1-지원-기능">3-1. 지원 기능</h2>

<p><img src="ARKIT%20by%20Apple%206407f08947234b0d81d09eca0ff82f4f/Untitled%201.png" alt="ARKIT%20by%20Apple%206407f08947234b0d81d09eca0ff82f4f/Untitled%201.png" /></p>

<p>기본적으로 제공하는 기능은 거의 동일하나</p>

<p>ARKIT → 3D Object Tracking / Body Tracking, 전 후면 카메라 동시 지원, Multiple Face Tracking의 <strong>추가적인 SDK 지원</strong>
<br /><br /></p>

<h2 id="3-2-범용성">3-2. 범용성</h2>

<ul>
  <li><strong>ARCORE</strong></li>
</ul>

<p>Android, iOS, Windows10에서 전부 구동 가능</p>

<p>Document → Unity, Unreal, Android, iOS 제공</p>

<p>Opensource</p>

<ul>
  <li><strong>ARKIT</strong></li>
</ul>

<p>iOS에서만 구동 가능하며 폐쇄적으로 Document, Opensource 제공 X
<br /><br /></p>

<h2 id="3-3-인식-기능-algorithm-방식">3-3. 인식 기능 (Algorithm 방식)</h2>

<ul>
  <li><strong>ARCORE</strong></li>
</ul>

<p>Feature Points를 최대한 많이 찾아, Mapping된 공간 영역을 빠르게 확장</p>

<ul>
  <li><strong>ARKIT</strong></li>
</ul>

<p>수평, 수직으로 평면을 감지하는 기술이 정확
<br /><br /></p>

<h2 id="3-4-지원-디바이스">3-4. 지원 디바이스</h2>

<ul>
  <li><strong>ARCORE</strong></li>
</ul>

<p>Google/ 하웨이/ LG/ 삼성/ 샤오미/ Apple 등 폭넓은 디바이스 지원</p>

<p>→ 하드웨어 성능, 지원하는 센서에 따라 ARCORE 성능이 많이 달라짐</p>

<ul>
  <li><strong>ARKIT</strong></li>
</ul>

<p>iPhone / iPad 의 iOS 기기만 지원</p>

<p>→ True Depth 카메라가 장착되어 있어 정확도가 상당히 높은 인식 기술 제공</p>

<p>→ 특히 LIDAR 부착된 장치의 경우, 고해상도의 Depth Map을 얻을 수 있어 AR 세계의 공간을 분석하고 인식하는 기술이 더욱 향상됨.</p>

<h1 id="4--class">4.  CLASS</h1>

<h2 id="4-1-arconfiguration">4-1. ARConfiguration</h2>

<p>→ AR에 필요한 것들을 구성하기 위한 추상 Class.</p>

<p>→ 이를 상속받은 8개의 서브클래스가 실질적인 작업을 한다.</p>

<p><img src="ARKIT%20by%20Apple%206407f08947234b0d81d09eca0ff82f4f/Untitled%202.png" alt="ARKIT%20by%20Apple%206407f08947234b0d81d09eca0ff82f4f/Untitled%202.png" /></p>

<p>→ ARWorldTrackingConfiguration</p>

<p>ARkit 기본 기능 제공, 사용자가 거주하는 실제 세계를 추적하고 가상 콘텐츠를 배치할 좌표 공간과 일치시킴</p>

<p>가상의 물체는 현실 세계의 카메라가 어떻게 움직이더라도 같은 곳에 위치해야 한다.</p>

<p><img src="ARKIT%20by%20Apple%206407f08947234b0d81d09eca0ff82f4f/Untitled%203.png" alt="ARKIT%20by%20Apple%206407f08947234b0d81d09eca0ff82f4f/Untitled%203.png" /></p>

<p>기기의 움직임을 3개의 회전각(roll, pitch, yaw)과 3개의 변환각 (x, y, z)을 통해 추적한다.</p>

<h1 id="5-scenekit">5. SCENEKIT</h1>

<p>Scenekit는 앱에서 3D 애니메이션 장면과 효과를 만드는 데 도움이 되는 고급 3D 그래픽 프래임워크.</p>

<p><img src="ARKIT%20by%20Apple%206407f08947234b0d81d09eca0ff82f4f/Untitled%204.png" alt="ARKIT%20by%20Apple%206407f08947234b0d81d09eca0ff82f4f/Untitled%204.png" /></p>

<blockquote>
  <p>모바일 환경에서 증강현실 혹은 3D 모델 랜더링을 요하는 어플리케이션을 개발할 때, OpenGL이나 Apple의 Metal과 같은 그래픽 API들을 표준으로 삼음.</p>

</blockquote>

<blockquote>
  <p>하지만 개발 시 매우 어려운 난이도나, 비효율성 등의 여러 문제 때문에 graphics rendering engine을 필요로 함 → <strong>SpriteKit, SceneKit</strong></p>

</blockquote>

<h2 id="5-1-spritekit">5-1. SpriteKit</h2>

<p>→ 단순 규모에서 2D 애니메이션을 위해 디자인 됨.</p>

<p>→ 개발자들에게 2D 애니메이션을 위한 모든 툴 제공.</p>

<h2 id="5-2-scenekit">5-2. SceneKit</h2>

<p>→ Core Animation Framework를 기반으로, SpriteKit에 비해 고성능 옵션을 제공하며, 사용시 상당한 수학과 기하학 요구</p>

<p>→ high-level 3D graphics framework로서, rendering engine과 descriptive API로 움직이는 장면을 만들기 위해 사용된다.</p>

<p>→ Metal과 같은 lower-level-API보다는 복잡하다.</p>

<p>→ Loin OS에서 배포되었으며, 개발자들이 보다 쉽게 복잡한 3D 장면을 만들 수 있도록 디자인 됨.</p>

<p>→ VR 용으로 고안되엇으며 ARKIT과 함께 사용할 수 밖에 없음.</p>

<div class="language-swift highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">@IBOutlet</span> <span class="k">weak</span> <span class="k">var</span> <span class="nv">sceneView</span><span class="p">:</span> <span class="kt">SCNView</span><span class="o">!</span>

<span class="n">sceneView</span><span class="o">.</span><span class="n">scene</span> <span class="o">=</span> <span class="kt">SCNScene</span><span class="p">()</span>
<span class="n">sceneView</span><span class="o">.</span><span class="n">autoenablesDefaultLighting</span> <span class="o">=</span> <span class="kc">true</span>
<span class="k">let</span> <span class="nv">boxNode</span> <span class="o">=</span> <span class="kt">SCNNode</span><span class="p">()</span>
<span class="n">boxNode</span><span class="o">.</span><span class="n">geometry</span> <span class="o">=</span> <span class="kt">SCNBox</span><span class="p">(</span><span class="nv">width</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span> <span class="nv">height</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span> <span class="nv">length</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span> <span class="nv">chamferRadius</span><span class="p">:</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">boxNode</span><span class="o">.</span><span class="n">geometry</span><span class="p">?</span><span class="o">.</span><span class="n">firstMaterial</span><span class="p">?</span><span class="o">.</span><span class="n">lightingModel</span> <span class="o">=</span> <span class="o">.</span><span class="n">physicallyBased</span>
<span class="n">boxNode</span><span class="o">.</span><span class="n">geometry</span><span class="p">?</span><span class="o">.</span><span class="n">firstMaterial</span><span class="p">?</span><span class="o">.</span><span class="n">diffuse</span><span class="o">.</span><span class="n">contents</span> <span class="o">=</span> <span class="kt">UIColor</span><span class="o">.</span><span class="n">red</span>
<span class="n">boxNode</span><span class="o">.</span><span class="n">geometry</span><span class="p">?</span><span class="o">.</span><span class="n">firstMaterial</span><span class="p">?</span><span class="o">.</span><span class="n">metalness</span><span class="o">.</span><span class="n">contents</span> <span class="o">=</span> <span class="mf">1.0</span>

<span class="n">sceneView</span><span class="o">.</span><span class="n">scene</span><span class="p">?</span><span class="o">.</span><span class="n">rootNode</span><span class="o">.</span><span class="nf">addChildNode</span><span class="p">(</span><span class="n">boxNode</span><span class="p">)</span>
</code></pre></div></div>

<p>→ 기본 View는 SCNView</p>

<ul>
  <li>보통 AR 증강현실 APP에서는 SceneKit를 사용해 왔음.</li>
</ul>

<p>→ SceneKit은 Contents들을 트리구조를 활용해서 실행.</p>

<p>→ root 노드는 시각적인 요소를 가지지 않으며, 해당 Scene world의 좌표를 정함.</p>

<p>→ 자식 노드들은 root 노드의 scene world 내에서 시각적인 요소로 존재하는 원리.</p>

<aside>
💡 Node (SCNNode) : root노드에 상대적인 좌표 위치 변환 속성을 제공함 (position, orientation, scale)

</aside>

<p>→ 보는 방향이 -z축 방향을 가리키는 우회 좌표계를 사용한다.</p>

<p><img src="ARKIT%20by%20Apple%206407f08947234b0d81d09eca0ff82f4f/Untitled%205.png" alt="ARKIT%20by%20Apple%206407f08947234b0d81d09eca0ff82f4f/Untitled%205.png" /></p>

<p><strong>SCENEKIT은 2017년 이후로 더 이상 업데이트 되지 않음</strong></p>

<p>→ 점점 사라질 예정</p>

<p>→ 하지만 아직도 RealityKit 2.0보다 몇몇 이점이 존재한다.</p>

<h1 id="6-realitykit-20">6. RealityKit 2.0</h1>

<p>기본 ARKit 통합, 물리적 요소 기반의 랜더링, 변형 및 스켈레톤 애니메이션, 공간 오디오 및 강체 물리 요소를 통해 AR 개발을 빠르고 쉽게 수행할 수 있게 해주는 프레임워크.</p>

<p><img src="ARKIT%20by%20Apple%206407f08947234b0d81d09eca0ff82f4f/Untitled%206.png" alt="ARKIT%20by%20Apple%206407f08947234b0d81d09eca0ff82f4f/Untitled%206.png" /></p>

<p>→ Apple의 랜더링 기술 제품군에서 가장 최신 SDK (2019년 출시)</p>

<p>→ AR/ VR 프로젝트 용으로 제작되었으며, iOS, mac에서 사용 가능</p>

<p>→ 다중 스레드 렌더링</p>

<p>→ LIDAR 스캐너 지원</p>

<p>→ 독립적으로 사용 가능하며, ARKIT, MetalKit와 함께 사용할 수 있다.</p>

<p>→ iPhone OS 15에서부터 접근 가능</p>

<div class="language-swift highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kd">@IBOutlet</span> <span class="k">weak</span> <span class="k">var</span> <span class="nv">arView</span><span class="p">:</span> <span class="kt">ARView</span><span class="o">!</span>
<span class="k">let</span> <span class="nv">box</span> <span class="o">=</span> <span class="kt">MeshResource</span><span class="o">.</span><span class="nf">generateBox</span><span class="p">(</span><span class="nv">size</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">)</span>
<span class="k">let</span> <span class="nv">material</span> <span class="o">=</span> <span class="kt">PhysicallyBasedMaterial</span><span class="p">()</span>
<span class="k">let</span> <span class="nv">model</span> <span class="o">=</span> <span class="kt">ModelEntity</span><span class="p">(</span><span class="nv">mesh</span><span class="p">:</span> <span class="n">box</span><span class="p">,</span> <span class="nv">materials</span><span class="p">:</span> <span class="p">[</span><span class="n">material</span><span class="p">])</span>

<span class="k">let</span> <span class="nv">anchor</span> <span class="o">=</span> <span class="kt">AnchorEntity</span><span class="p">(</span><span class="nv">world</span><span class="p">:</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">anchor</span><span class="o">.</span><span class="nf">addChild</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>

<span class="n">arView</span><span class="o">.</span><span class="n">scene</span><span class="o">.</span><span class="n">anchors</span><span class="o">.</span><span class="nf">append</span><span class="p">(</span><span class="n">anchor</span><span class="p">)</span>
</code></pre></div></div>

<p>→ 기본 View는 ARView</p>
:ET